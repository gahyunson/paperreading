# VGGNet paper Review

Click HERE to Move paper : [VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION](https://arxiv.org/pdf/1409.1556.pdf) 

<aside>
ğŸ’¡ This paper evaluates networks with increasing depth using an architecture that employs small 3x3 convolution filters, resulting in a depth of 16-19 weight layers. The use of small filters allows for stable increase in network depth by adding more convolutional layers.

</aside>

## CONVNET CONFIGURATIONS

### 1. **Architecture**

| input convNets | image data - 224 x 224 RGB ê³ ì • |
| --- | --- |
| input image preprocess | (training image data - RGB í‰ê· ê°’)  |
| input filters | 1 x 1 (input image channelsë¥¼ ì„ í˜• ë³€í™˜í•¨) |
| receptive field | 3 x 3 convolution layers  |
| convolution | stride : 1px ê³ ì • |
| hidden layersì˜ activation | non-linearity(ReLU) |
| padding | 1px to 3 x 3 convolutional layers |
| pool layers | max pooling layers 5ê°œ |
|  | 2 x 2 filter , stride : 2 |
| convolutional layers | Fully-Connected layers 3ê°œ |
|  | 4096 channels + 4096 channels + 1000 channels |
| final layer | the soft-max layer |

receptive fieldì™€ input filterì˜ ì°¨ì´ëŠ” ë¬´ì—‡ì¼ê¹Œ?

- receptive field : input dataë¥¼ ë³´ëŠ” í¬ê¸°
- input filter : input dataë¥¼ ì „ì²˜ë¦¬í•˜ëŠ” í•„í„°

### 2. Configurations

ë…¼ë¬¸ì˜ Table 1ì— A to E ì—´ì„ ì´ìš©í•˜ì—¬ netsì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•œë‹¤. 

ë²”ìœ„ëŠ” A ë„¤íŠ¸ì›Œí¬ì—ì„œëŠ” 11ê°œ ë ˆì´ì–´, E ë„¤íŠ¸ì›Œí¬ì—ì„œëŠ” 19ê°œ ë ˆì´ì–´ì´ë‹¤. ë‰´ëŸ°ì˜ ë²”ìœ„ëŠ” 64ê°œ ~ 512ê°œì´ë‹¤. Table2 ì—ì„œëŠ” íŒŒë¼ë¯¸í„° ê°’ì„ë³¼ ìˆ˜ ìˆë‹¤. í•´ë‹¹ í…Œì´ë¸”ë§Œ ë´ë‘ êµ¬í˜„ì´ ê°€ëŠ¥í•  ë“¯ í•˜ë‹¤.

### 3. Discussion

- 3x3 filter 3ê°œ = 7x7 filter 1ê°œ
- íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ë” ì ë‹¤ = ì—°ì‚°ëŸ‰ì´ ë” ì ë‹¤ = ë¹ ë¥´ê²Œ ê²°ê³¼ ë„ì¶œ ê°€ëŠ¥

ì˜ˆì‹œ) C channelsë¥¼ ê°€ì§„ë‹¤ê³  ê°€ì •í•  ë•Œ 3x3 conv stack 3ê°œì˜ íŒŒë¼ë¯¸í„° ê°’ì€ 27$C^2$ì´ê³  7x7 1ê°œì˜ íŒŒë¼ë¯¸í„° ê°’ì€ 49$C^2$ì´ë‹¤. 

- 1x1 conv.layers : ë¹„ì„ í˜•ì„± ì¦ê°€ (receptive fieldì˜ ì˜í–¥ì—†ì´)
- 7x7 ë³´ë‹¤ 3x3 í•„í„°ê°€ ë” ì¢‹ì€ ì´ìœ ëŠ”? ë” ì‘ì€ í•„í„°ë¥¼ ì‚¬ìš©í•˜ë©´ ë” ë§ì€ ë¹„ì„ í˜•ì„± ê²°ê³¼ë¥¼ ê°€ì§ˆ ìˆ˜ ìˆë‹¤. ì´ë¯¸ì§€ì˜ ë” ë§ì€ íŠ¹ì§•ì„ ì¶”ì¶œí•  ìˆ˜ ìˆê²Œ ëœë‹¤.

---

## Classification Framework

### 1. Training

|  | mini-batch gradient descent with momentum (multinomial logistic regression) |
| --- | --- |
| batch size | 256 |
| momentum | 0.9 |
| regularisation | L2 penalty |
| dropout | 0.5 (1st, 2nd fc layers) |
| learning rate | ì´ˆê¸°ê°’ : $10^{-2}$
validation accuracy ì¦ê°€ê°€ ë©ˆì¶œ ë•Œë§ˆë‹¤ 0.01(10ë°°ì”©) decrease
ê²°ê³¼ â†’ 3 times ê°ì†Œí•˜ê²Œ ë¨, 370K(74 epochs) ë°˜ë³µí•´ì„œ ë©ˆì¶¤ |
| input image | 224x224 ê³ ì •
+ ëœë¤ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ rescaleí•˜ì—¬ 224 í¬ê¸°ë¡œ ìë¦„,
+ ìë¥¸ ì´ë¯¸ì§€ë¥¼ ìˆ˜í‰ìœ¼ë¡œ ë’¤ì§‘ê±°ë‚˜ ëœë¤í•˜ê²Œ RGB ê°’ì„ ë³€ê²½ |
|  | 384 í¬ê¸°ì˜ ì´ë¯¸ì§€ë¡œ ì‚¬ì „í›ˆë ¨ëœ a single-scale model ì˜ fine-tuning â†’ configurationìœ¼ë¡œ multi-scale modelsë¥¼ í›ˆë ¨ |

> ë…¼ë¬¸ì˜ ì €ìë“¤ì€ ë§ì€ íŒŒë¼ë¯¸í„°ì™€ ê¹Šì€ ê¹Šì´ë¥¼ ê°€ì§„ netsê°€ `implicit regularisation`ì™€ íŠ¹ì •ì¸µì˜ ë ˆì´ì–´ ì´ˆê¸°ê°’ìœ¼ë¡œ ì¸í•´ì„œ ì ì€ epochsë¡œ ìˆ˜ë ´ëœë‹¤ ì§ì‘í–ˆë‹¤. The initialisation of the network weightsì´ ì¤‘ìš”í•˜ë‹¤ íŒë‹¨í•¨.
> 

â†’ ë¬¸ì œì  : ê¹Šì€ netsì—ì„œ ë‚˜ìœ ì´ˆê¸°ê°’ì€ í•™ìŠµì„ ë©ˆì¶”ê²Œ í•˜ê±°ë‚˜ gradientë¥¼ ë¶ˆì•ˆì •í•˜ê²Œ í•  ìˆ˜ ìˆë‹¤.

â†’ í•´ê²° ë°©ë²• : Table 1ì˜ ìƒëŒ€ì ìœ¼ë¡œ ì ì€ ë ˆì´ì–´ì¸ A configuration ìœ¼ë¡œ ëœë¤ ì´ˆê¸°ê°’ìœ¼ë¡œ í›ˆë ¨ ë°˜ë³µ(learning rate ê°ì†Œì•ˆí•¨) â†’ training architecturesê°€ ë” ê¹Šì–´ì¡Œì„ ë•Œ í•´ë‹¹ ê°’ìœ¼ë¡œ ì²˜ìŒ 4ê°œ conv layersì™€ ë§ˆì§€ë§‰ fc layers 3ê°œ ì´ˆê¸°ê°’ ì„¤ì •(ë‚˜ë¨¸ì§€ëŠ” ëœë¤ , ë²”ìœ„ëŠ” 0 ~ $10^{-2}$), biases : 0ë¡œ ì´ˆê¸°í™”. 

â†’ ê²°ë¡  : íƒ€ ë…¼ë¬¸ì„ í†µí•´ pre-training ì—†ì´ë„ ì´ˆê¸°ê°’ ì„¤ì •ì´ ê°€ëŠ¥í•¨ì„ ì•Œì•„ëƒ„.

### 2. Testing

| test input scale | train input scaleì´ ê°™ì§€ ì•Šì•„ë„ ëœë‹¤ |
| --- | --- |
|  | horizontal flipping ì´ë¯¸ì§€ ì‚¬ìš© |
| the fully-convolutional network | ì•ì„œ 3ê°œì˜ fc layerë¥¼ test í•  ë•Œ ì•„ë˜ì™€ ê°™ì´ ë°”ê¿ˆ
1st fc layer â†’ 7x7 conv. layer
2nd, 3rd fc layer â†’ 1x1 conv. layer |
|  | ìë¥´ì§€ ì•Šì€ ì „ì²´ ì´ë¯¸ì§€ê°€ ì ìš©ë¨(conv.ë¡œë§Œ ì´ë£¨ì–´ì¡Œê¸° ë•Œë¬¸, ë”°ë¡œ ì´ë¯¸ì§€ë¥¼ ì˜ë¼ì„œ inputê°’ìœ¼ë¡œ ë„£ëŠ” ì‘ì—…ì„ ì•ˆí•´ë„ ëœë‹¤) |
| final layer ê²°ê³¼ (softmax ì§ì „) | a class score map size = ì´ë¯¸ì§€ í¬ê¸°ê°€ ê°™ìœ¼ë©´ ëŠ˜ ê°™ì€ ê°’ì´ ë‚˜ì˜´ |
| final score | = spatially averaged = original imagesì™€ flipped images ì˜ í‰ê· ê°’ |
| multi-crop evaluation  | ì„œë¡œ ë‹¤ë¥¸ conv. ê²½ê³„ ì¡°ê±´ì„ ê°€ì ¸ì„œ dense evaluationê³¼ ìƒí˜¸ë³´ì™„ì ì¸ ê²ƒ |
|  | ConvNet ì„ a cropì— ì ìš© â†’ paddig : 0 |
| dense evaluation | 0 paddingì´ ì•„ë‹Œ crop í•œ ì£¼ë³€ì˜ ë¶€ë¶„ë“¤ì„ padding ê°’ìœ¼ë¡œ ì‚¬ìš© |
|  | Receptive field í¬ê¸° ì¦ê°€ |

### 3. Implementation details

- the publicly available C++ Caffe toolbox ì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬í˜„ë¨
- í•˜ë‚˜ì˜ ì‹œìŠ¤í…œì— ì„¤ì¹˜ëœ ì—¬ëŸ¬ ê°œì˜ GPUì—ì„œ train, evaluate + ë‹¤ì–‘í•œ cropí•˜ì§€ ì•Šì€ ì´ë¯¸ì§€ í•™ìŠµ ë° í‰ê°€ ìˆ˜í–‰
- GPUê°€ ë³‘ë ¬ ì²˜ë¦¬í•˜ì—¬ë„ GPU ë°°ì¹˜ ê¸°ìš¸ê¸°(ì „ì²´ ë°°ì¹˜ í‰ê·  ê¸°ìš¸ê¸° ì ìš©)ê°€ ë™ì¼í•˜ê²Œ ì ìš©ë˜ë¯€ë¡œ ë‹¨ì¼ GPUì™€ ì •í™•íˆ ë™ì¼í•œ ê²°ê³¼ ì¶”ì¶œ ê°€ëŠ¥
- a single GPU ì†ë„ < an off-the-shelf 4-GPU (4ê°œì˜ GPU ì¥ì°© ì‹œìŠ¤í…œ)  [3.75ë°° ë” ë¹ ë¦„]
- NVIDIA Titan Black GPUsë¡œ 2~3ì£¼ í•™ìŠµ ì‹œê°„ ì†Œìš”

---

## Classification experiments

| Class | 1000ê°œ |
| --- | --- |
| train image |  1.3M |
| validation image | 50K |
| test image | 100K |

(validation setì„ test setìœ¼ë¡œ ì‚¬ìš©í•¨)

ë¶„ë¥˜ ì„±ëŠ¥ì€ ë‘ ê°€ì§€ ê¸°ì¤€(top-1, top-5 ì—ëŸ¬ìœ¨)ìœ¼ë¡œ ì¸¡ì •ëë‹¤. 

- top-1 : multi-class classification error ì˜ëª» ë¶„ë¥˜ëœ ì´ë¯¸ì§€ ë¹„ìœ¨
- top-5 : ìƒìœ„ 5ê°œ ì˜ˆì¸¡ ì¹´í…Œê³ ë¦¬ ë°–ì˜ ì´ë¯¸ì§€ ë¹„ìœ¨ (main evaluation ì£¼ìš” í‰ê°€ ê¸°ì¤€ criterion used in ILSVRC)

### 1. Single scale evaluation

scale ê°’ì„ ë‘ ê°€ì§€(256, 384) ê³ ì •í•˜ê³  í›ˆë ¨ 

256x256 : ì‚¬ì „ í›ˆë ¨ìš©, ì´í›„ 384 í›ˆë ¨ì— ì‚¬ì „ í›ˆë ¨ ëª¨ë¸ë¡œ ì‚¬ìš©ë¨, lr: $10^{-3}$

384x384 : 256 ì‚¬ì „ í›ˆë ¨ì„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ì†ë„ê°€ ë” ë¹ ë¦„, 256 í›ˆë ¨ì‹œ ë‚˜ì˜¨ ê°€ì¤‘ì¹˜ ì‚¬ìš©, ë” ì‘ì€ learning rate ê°’ ì‚¬ìš©

### 2. Multi-scale evaluation

S ê°’ì„ multi-scale ì„ í†µí•´ì„œ ì„¤ì •í•œë‹¤

256 ~ 512 ì‚¬ì´ì˜ Së¡œ ëœë¤ ìƒ˜í”Œë§í•˜ì—¬ í›ˆë ¨ (=scale jittering)

ì†ë„ì˜ ì´ìœ ë¡œ ì•ì„œ 384ë¡œ í›ˆë ¨í•œ ë™ì¼ configurationì˜ single scale modelì˜ ëª¨ë“  ë ˆì´ì–´ë¥¼  fine-tuningí•˜ì—¬ multi-scale modelsë¥¼ í›ˆë ¨

### 3. Multi-crop evaluation

**dense Conv evaluation** vs **mult-crop evaluation**

ìƒë‹¨ ë‘ ê°€ì§€ evaluationì˜ í‰ê· ìœ¼ë¡œ softmax outputì„ ì¶”ì¶œ

### 4. ConvNet fusion

ëª‡ ê°œì˜ ëª¨ë¸ë“¤ì˜ output evaluationì„ í‰ê· ë‚´ëŠ” ê²ƒìœ¼ë¡œ ì„±ëŠ¥ì„ ë†’ì„.

single-scale networks , a multi-scale model (fully-connected ë¶€ë¶„ë§Œ fine-tuning í•œ ëª¨ë¸) ìœ¼ë¡œë§Œ í›ˆë ¨.

â†’ test error : 7.3% (7ê°œ networks ì•™ìƒë¸” ëª¨ë¸)

â†’ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ multi-sclae models 2ê°œë¡œ ì•™ìƒë¸” ì‹œë„

7.3% ì—ëŸ¬ë¡œ 2ë“±ì„ í–ˆë‹¤. ì•™ìƒë¸” 2ê°œ ëª¨ë¸ì„ ì´ìš©í•œ ê²°ê³¼ë¡œëŠ” 6.8% ì—ëŸ¬ìœ¨ì´ ë‚˜ì™”ë‹¤. (D/[256;512]/256,384,512), (E/[256;512]/256,384,512) 

â†’ test error : 7.0% (with dense)

â†’ test error : 6.8% (with dense & multi-crop)

â†’ test error : 7.1% (with single model)

(dense & multi-cropì˜ ì¡°í•©ì´ ê°€ì¥ ì¢‹ì€ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤)

## Conclusion

ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ìœ„í•œ ìµœëŒ€ 19ê°œ ì¸µì˜ convolutional networksë¥¼ ë§Œë“¤ì—ˆë‹¤. í° ë°ì´í„°ì…‹ì„ì—ë„ convolutional networksë¡œ ê¹Šì€ ë ˆì´ì–´ ì„¤ê³„ê°€ ê°€ëŠ¥í•œ ê²ƒì„ ë³´ì—¬ì¤¬ê³ , ê¹Šì´ê°€ ì¤‘ìš”ì„±ì„ ì•Œë ¤ì¤€ë‹¤.